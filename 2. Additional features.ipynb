{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bdf79e1",
   "metadata": {},
   "source": [
    "# Import section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff9aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, re, json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from googlemaps import Client as GoogleMaps\n",
    "import googlemaps\n",
    "import gmaps\n",
    "from keplergl import KeplerGl\n",
    "import geopandas as gpd\n",
    "from yelpapi import YelpAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9c08c2",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebc6c72",
   "metadata": {},
   "source": [
    "After scraping the real Estate data I would like to collect some additional features for the modeling. For this i will use different sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299b7b69",
   "metadata": {},
   "source": [
    "# Yelp API client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e110bd1f",
   "metadata": {},
   "source": [
    "As a first instance I will set up an api account for yelp to scrape several data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cc113cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = XXXX\n",
    "client_id = XXXX\n",
    "# key and client id have been deleted for the github version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a88cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_api = YelpAPI(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3153256",
   "metadata": {},
   "source": [
    "Unfortunately the yelp api client is limited to 5.000 request per day and within one request the maximum result is 50. To maximize the outcome i will include some search criteria and drop the outliers at the end. \n",
    "\n",
    "For the criteria i will use the postcodes of London as location and also the price categories from yelp. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6886860",
   "metadata": {},
   "source": [
    "For the postcodes i found a CSV provided by the london goverment under https://data.london.gov.uk/dataset/postcode-directory-for-london"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce78616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postcodes = pd.read_csv(\"london_postcodes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b9b96e",
   "metadata": {},
   "source": [
    "The data includes a lot of information which we don't need so we will clean it first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec761102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pcd', 'pcd2', 'pcds', 'dointr', 'doterm', 'oscty', 'ced', 'oslaua',\n",
       "       'osward', 'parish', 'usertype', 'oseast1m', 'osnrth1m', 'osgrdind',\n",
       "       'oshlthau', 'nhser', 'ctry', 'rgn', 'streg', 'pcon', 'eer', 'teclec',\n",
       "       'ttwa', 'pct', 'itl', 'statsward', 'oa01', 'casward', 'park', 'lsoa01',\n",
       "       'msoa01', 'ur01ind', 'oac01', 'oa11', 'lsoa11', 'msoa11', 'wz11', 'ccg',\n",
       "       'bua11', 'buasd11', 'ru11ind', 'oac11', 'lat', 'long', 'lep1', 'lep2',\n",
       "       'pfa', 'imd', 'calncv', 'stp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_postcodes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b9d524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postcodes = df_postcodes[['pcd', 'lat', 'long']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ed32b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postcodes.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ecc3ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326214"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_postcodes = df_postcodes['pcd'].tolist()\n",
    "len(london_postcodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e267e9d",
   "metadata": {},
   "source": [
    "The more detailed postcode list is huge, I will save it for later but for our scraping we will clean the column more. I only want to have the first three digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61129ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postcodes_short = df_postcodes[\"pcd\"].apply(lambda x: x[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21a865ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326214,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_postcodes_short.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4365bf",
   "metadata": {},
   "source": [
    "As a lot of postcode have the same first three digits i will drop the duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a84dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postcodes_short = df_postcodes_short.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77c34f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_postcodes_short.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cd19b4",
   "metadata": {},
   "source": [
    "As the dataframe is very big and causing an issue for the push request on github i am saving the short version within the folder and keep the full file as backup on my computer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "972626ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postcodes_short.to_csv(f'df_postcodes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591dbcdb",
   "metadata": {},
   "source": [
    "we will directly load it again to have a save point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de77818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postcodes_short = pd.read_csv(\"df_postcodes.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2198e18b",
   "metadata": {},
   "source": [
    "Finally i will create a list of the postcodes which will be used for the yelp api to iterate through the different locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e512fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcode_short = df_postcodes_short[\"pcd\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae00d691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(postcode_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32bd3bf",
   "metadata": {},
   "source": [
    "# Additional Features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3043b365",
   "metadata": {},
   "source": [
    "## Gyms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7092350e",
   "metadata": {},
   "source": [
    "As a first additional feature I want to include the locations of gyms in London. I will use the Yelp api to extract the information about the gyms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a2b7ad",
   "metadata": {},
   "source": [
    "**Normal search for \"gym\" in London**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fbc2576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = yelp_api.search_query(term = \"Gym\",\n",
    "                                 location = \"London\",\n",
    "                                 limit = 50)\n",
    "\n",
    "cols = list(response['businesses'][0].keys())\n",
    "df_gym = pd.DataFrame(columns=cols)\n",
    "for biz in response['businesses']:\n",
    "    df_gym = df_gym.append(biz, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062fbfe4",
   "metadata": {},
   "source": [
    "I did a first test run to evaluate if the api is working and to have a first look at the data. After this i will scrape all of the data for the different postcodes which i created above and also for different price categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e405b3c",
   "metadata": {},
   "source": [
    "**Different using the different postcodes and price categories for the api**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4266037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in postcode_short:\n",
    "    for price in range(1,5):\n",
    "        response = yelp_api.search_query(term = \"Gym\",\n",
    "                                 location = i,\n",
    "                                 categories = \"gyms, All\",\n",
    "                                 price = price, \n",
    "                                 limit = 50)\n",
    "        \n",
    "        for biz in response['businesses']:\n",
    "            df_gym = df_gym.append(biz, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1d2370b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gym.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5805285d",
   "metadata": {},
   "source": [
    "To avoid duplicates i will directly drop all of them based on the id of the business:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4f50d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gym = df_gym.drop_duplicates('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38898d1d",
   "metadata": {},
   "source": [
    "I would need to extract the latitude and longitude from the coordinates column to make it usable for my analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbd590b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will create two functions to extract the coordinates and transform them into floats\n",
    "def extract_lat (i):\n",
    "    try:\n",
    "        lat = float(i.split(\" \")[1].replace(\",\",\"\"))\n",
    "        return lat\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def extract_long (i):\n",
    "    try:\n",
    "        long = float(i.split(\" \")[3].replace(\"}\",\"\"))\n",
    "        return long\n",
    "    except:\n",
    "        return np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5990ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gym[\"gym_lat\"] = df_gym[\"coordinates\"].apply(extract_lat)\n",
    "df_gym[\"gym_long\"] = df_gym[\"coordinates\"].apply(extract_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0af97e6",
   "metadata": {},
   "source": [
    "I will only need certain columns so i will exclude the not needed ones and also reduce tha size of the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc217f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gym = df_gym[[\"name\", \"review_count\", \"rating\", \"price\", \"gym_lat\", \"gym_long\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef98d091",
   "metadata": {},
   "source": [
    "Last but not least i will save the csv for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89efd2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gym.to_csv(f'df_gym.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49967d8",
   "metadata": {},
   "source": [
    "## Supermarkets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e13aa",
   "metadata": {},
   "source": [
    "Also here we will us the api from Yelp to collect the different locations of different grocery stores in London. The procedure is exactly the same as for the gyms. The only difference is that i will scrape for different supermarket names: Tesco, Marks and Spencer, Whole Foods and Sainsbury."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f315ca",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  Tesco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a5719b14",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "response = yelp_api.search_query(term = \"Tesco\",\n",
    "                                 location = \"London\",\n",
    "                                 limit = 50,\n",
    "                                 categories = \"grocery\")\n",
    "\n",
    "cols = list(response['businesses'][0].keys())\n",
    "df_tesco = pd.DataFrame(columns=cols)\n",
    "for biz in response['businesses']:\n",
    "    df_tesco = df_tesco.append(biz, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "979fff88",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 216/216 [10:37<00:00,  2.95s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(postcode_short):\n",
    "    for price in range(1,5):\n",
    "        try:\n",
    "            response = yelp_api.search_query(term = \"Tesco\",\n",
    "                                 location = str(i),\n",
    "                                 price = price, \n",
    "                                 limit = 50,\n",
    "                                 categories = \"grocery\")\n",
    "        \n",
    "            for biz in response['businesses']:\n",
    "                df_tesco = df_tesco.append(biz, ignore_index=True)\n",
    "        except: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154706d9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Drop of duplicates based on the business id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "068dfa5e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_tesco = df_tesco.drop_duplicates('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702eefe7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After reviewing the data i realized that yelp also provided me with other supermarkets. I will filter the dataframe by the name to only receive tesco markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "34dc1ee0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_tesco = df_tesco[df_tesco[\"name\"].str.contains(\"Tesco\" or \"tesco\")]\n",
    "df_tesco.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a5f3b9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Saving the data for safety:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175353de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_tesco.to_csv(f'df_tesco.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ed574",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Marks and Spencer (only supermarkets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75e8d23d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "response = yelp_api.search_query(term = \"marks & spencer\",\n",
    "                                 location = \"London\",\n",
    "                                 limit = 50,\n",
    "                                 categories = \"grocery\")\n",
    "\n",
    "cols = list(response['businesses'][0].keys())\n",
    "df_marks = pd.DataFrame(columns=cols)\n",
    "for biz in response['businesses']:\n",
    "    df_marks = df_marks.append(biz, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b8ecc57",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 216/216 [06:50<00:00,  1.90s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(postcode_short):\n",
    "    for price in range(1,5):\n",
    "        try:\n",
    "            response = yelp_api.search_query(term = \"marks & spencer\",\n",
    "                                 location = str(i),\n",
    "                                 price = price, \n",
    "                                 categories = \"grocery\",           \n",
    "                                 limit = 50)\n",
    "        \n",
    "            for biz in response['businesses']:\n",
    "                df_marks = df_marks.append(biz, ignore_index=True)\n",
    "        except: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4763ef16",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# droping duplicates\n",
    "df_marks = df_marks.drop_duplicates('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "407b1c2f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_marks = df_marks[df_marks[\"name\"].str.contains(\"Marks\")]\n",
    "df_marks.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d076bad1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Saving the data for safety:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21897c6b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_marks.to_csv(f'df_marks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0177569f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Whole Foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "504fbe29",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "response = yelp_api.search_query(term = \"Whole Foods Market\",\n",
    "                                 location = \"London\",\n",
    "                                 limit = 50,\n",
    "                                 categories = \"grocery\")\n",
    "\n",
    "cols = list(response['businesses'][0].keys())\n",
    "df_whole = pd.DataFrame(columns=cols)\n",
    "for biz in response['businesses']:\n",
    "    df_whole = df_whole.append(biz, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f7b90d40",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 216/216 [10:26<00:00,  2.90s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(postcode_short):\n",
    "    for price in range(1,5):\n",
    "        try:\n",
    "            response = yelp_api.search_query(term = \"Whole Foods Market\",\n",
    "                                 location = str(i),\n",
    "                                 price = price, \n",
    "                                 categories = \"grocery\",           \n",
    "                                 limit = 50)\n",
    "        \n",
    "            for biz in response['businesses']:\n",
    "                df_whole = df_whole.append(biz, ignore_index=True)\n",
    "        except: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "84204eaf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# droping duplicates\n",
    "df_whole = df_whole.drop_duplicates('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d97b3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Droping lines which dont include whole foods in their name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a68cf7e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_whole = df_whole[df_whole[\"name\"].str.contains(\"Whole Foods\" or \"whole foods\")]\n",
    "df_whole.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4c7ed812",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_whole.to_csv(f'df_whole.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b0d07",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Sainsbury’s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "3eca9f6a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "response = yelp_api.search_query(term = \"Sainsbury's\",\n",
    "                                 location = \"London\",\n",
    "                                 limit = 50,\n",
    "                                 categories = \"grocery\")\n",
    "\n",
    "cols = list(response['businesses'][0].keys())\n",
    "df_sains = pd.DataFrame(columns=cols)\n",
    "for biz in response['businesses']:\n",
    "    df_sains = df_whole.append(biz, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "46aad931",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 216/216 [09:59<00:00,  2.78s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(postcode_short):\n",
    "    for price in range(1,5):\n",
    "        try:\n",
    "            response = yelp_api.search_query(term = \"Sainsbury's\",\n",
    "                                 location = str(i),\n",
    "                                 price = price, \n",
    "                                 categories = \"grocery\",           \n",
    "                                 limit = 50)\n",
    "        \n",
    "            for biz in response['businesses']:\n",
    "                df_sains = df_sains.append(biz, ignore_index=True)\n",
    "        except: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "28c4949c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# droping duplicates\n",
    "df_sains = df_sains.drop_duplicates('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "610b54cd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# reviewing name column and droping non sainsbury stores\n",
    "df_sains = df_sains[df_sains[\"name\"].str.contains(\"Sainsbury\" or \"sainsbury\")]\n",
    "df_sains.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "af241143",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sains.to_csv(f'df_sains.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439997f1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Merging the Supermarket datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a86501b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Above we scraped the information for several supermarkets. For Safety reason i saved the dataframes. Now i will load all of them and merge them into one dataframe for the supermarkets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a814853",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_tesco = pd.read_csv(\"df_tesco.csv\", index_col = 0)\n",
    "df_marks = pd.read_csv(\"df_marks.csv\", index_col = 0)\n",
    "df_whole = pd.read_csv(\"df_whole.csv\", index_col = 0)\n",
    "df_sains = pd.read_csv(\"df_sains.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3adf60b9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_grocery = pd.concat([df_tesco, df_marks, df_whole, df_sains], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dbde2f20",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_grocery[\"grocery_lat\"] = df_grocery[\"coordinates\"].apply(extract_lat)\n",
    "df_grocery[\"grocery_long\"] = df_grocery[\"coordinates\"].apply(extract_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd52cac",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For our further analysis we will only need the columns [\"name\", \"review_count\", \"rating\", \"price\", \"grocery_lat\", \"grocery_long\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2f16d914",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_grocery = df_grocery[[\"name\", \"review_count\", \"rating\", \"price\", \"grocery_lat\", \"grocery_long\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060db22f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Adjusting the column with the names of the stores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ef24918",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sainsbury's                100\n",
       "Tesco Express               71\n",
       "Tesco                       65\n",
       "Tesco Stores                36\n",
       "Marks and Spencer           28\n",
       "Whole Foods Market          25\n",
       "Sainsburys                  21\n",
       "Tesco Superstore            18\n",
       "Tesco Metro                 16\n",
       "Sainsburys Supermarkets     10\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grocery[\"name\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133c3bfd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I would like to unify the name column more. It should only include \"Sainsbury\", \"Tesco\", \"Marks and Spencer\" and \"Whole Foods\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "51eb22b3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def adj_names_supermarkets(i):\n",
    "    if \"tesco\" in i.lower():\n",
    "        return \"Tesco\"\n",
    "    elif \"sainsb\" in i.lower():\n",
    "        return \"Sainsbury\"\n",
    "    elif \"marks\" in i.lower():\n",
    "        return \"Marks and Spencer\"\n",
    "    elif \"whole\" in i.lower():\n",
    "        return \"Whole Foods\"\n",
    "    else:\n",
    "        return \"NAN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0976e18c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_grocery[\"name\"] = df_grocery[\"name\"].apply(adj_names_supermarkets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "948898e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesco                224\n",
       "Sainsbury            146\n",
       "Marks and Spencer     40\n",
       "Whole Foods           30\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grocery[\"name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "106502de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_grocery.to_csv(f'df_grocery.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e853f81",
   "metadata": {},
   "source": [
    "## Public transport stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f46083",
   "metadata": {},
   "source": [
    "The Zoopla website provided already some information about the close by public transport positions. But i would like to have the ability to calculate the distance on my own. For this reason i will include a DataFrame with information about tube and train station in London. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97819a2f",
   "metadata": {},
   "source": [
    "I found the website https://www.doogal.co.uk/london_stations.php which collected already all London tube and train stations with their coordinates. The data is provided as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de88ba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tube = pd.read_csv(\"Londonstations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1926551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>OS X</th>\n",
       "      <th>OS Y</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Zone</th>\n",
       "      <th>Postcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbey Road</td>\n",
       "      <td>539081</td>\n",
       "      <td>183352</td>\n",
       "      <td>51.531952</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>3</td>\n",
       "      <td>E15 3NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbey Wood</td>\n",
       "      <td>547297</td>\n",
       "      <td>179002</td>\n",
       "      <td>51.490784</td>\n",
       "      <td>0.120272</td>\n",
       "      <td>4</td>\n",
       "      <td>SE2 9RH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acton Central</td>\n",
       "      <td>520613</td>\n",
       "      <td>180299</td>\n",
       "      <td>51.508757</td>\n",
       "      <td>-0.263430</td>\n",
       "      <td>2</td>\n",
       "      <td>W3 6BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acton Main Line</td>\n",
       "      <td>520296</td>\n",
       "      <td>181196</td>\n",
       "      <td>51.516886</td>\n",
       "      <td>-0.267690</td>\n",
       "      <td>3</td>\n",
       "      <td>W3 9EH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acton Town</td>\n",
       "      <td>519457</td>\n",
       "      <td>179639</td>\n",
       "      <td>51.503071</td>\n",
       "      <td>-0.280303</td>\n",
       "      <td>3</td>\n",
       "      <td>W3 8HN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>Woodside Park</td>\n",
       "      <td>525725</td>\n",
       "      <td>192564</td>\n",
       "      <td>51.617868</td>\n",
       "      <td>-0.185426</td>\n",
       "      <td>4</td>\n",
       "      <td>N12 8SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>Woolwich</td>\n",
       "      <td>543931</td>\n",
       "      <td>178994</td>\n",
       "      <td>51.491578</td>\n",
       "      <td>0.071819</td>\n",
       "      <td>4</td>\n",
       "      <td>SE18 6EU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>Woolwich Arsenal</td>\n",
       "      <td>543754</td>\n",
       "      <td>178803</td>\n",
       "      <td>51.489907</td>\n",
       "      <td>0.069194</td>\n",
       "      <td>4</td>\n",
       "      <td>SE18 6HX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>Woolwich Dockyard</td>\n",
       "      <td>542738</td>\n",
       "      <td>178908</td>\n",
       "      <td>51.491108</td>\n",
       "      <td>0.054612</td>\n",
       "      <td>3</td>\n",
       "      <td>SE18 5JY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>Worcester Park</td>\n",
       "      <td>522192</td>\n",
       "      <td>166133</td>\n",
       "      <td>51.381104</td>\n",
       "      <td>-0.245575</td>\n",
       "      <td>4</td>\n",
       "      <td>KT4 7ND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>653 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Station    OS X    OS Y   Latitude  Longitude Zone  Postcode\n",
       "0           Abbey Road  539081  183352  51.531952   0.003723    3   E15 3NB\n",
       "1           Abbey Wood  547297  179002  51.490784   0.120272    4   SE2 9RH\n",
       "2        Acton Central  520613  180299  51.508757  -0.263430    2    W3 6BH\n",
       "3      Acton Main Line  520296  181196  51.516886  -0.267690    3    W3 9EH\n",
       "4           Acton Town  519457  179639  51.503071  -0.280303    3    W3 8HN\n",
       "..                 ...     ...     ...        ...        ...  ...       ...\n",
       "648      Woodside Park  525725  192564  51.617868  -0.185426    4   N12 8SE\n",
       "649           Woolwich  543931  178994  51.491578   0.071819    4  SE18 6EU\n",
       "650   Woolwich Arsenal  543754  178803  51.489907   0.069194    4  SE18 6HX\n",
       "651  Woolwich Dockyard  542738  178908  51.491108   0.054612    3  SE18 5JY\n",
       "652     Worcester Park  522192  166133  51.381104  -0.245575    4   KT4 7ND\n",
       "\n",
       "[653 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e4609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
